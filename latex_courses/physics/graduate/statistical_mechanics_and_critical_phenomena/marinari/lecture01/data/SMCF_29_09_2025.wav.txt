 indeed for many of you this is probably the first course in English
 what I want to say is that the course will be in English but I'm available to think your questions can be in Italian
 do many questions I mean this is not a completely trivial course we will discuss
 right so if you have a problem just ask I mean I will repeat I will go back you can tell me during the course and even after the hour and I will repeat something even when I start next time if you realize that you didn't get something you can ask I'm here and again we can interrupt also in Italian so
 in English I will try to speak slowly in the kind of understandable ways I mean you're lucky because you're Italian my accent is Italian so if you are not Italian it would be worth it of course as well as okay but I mean being Italian with my accent so yes this is more or less it so let me start from
 something technical that is new and that we can see why the moon is so full this course was not compulsory now it became compulsory for the curriculum of statistical economics so I've been thinking a bit about my study problem and I understand and recognize that there are some little
 parts that are a bit complicated not so much but a little bit so this is a course with some level of formality in some sense nothing dramatic but this is a course in which you try to be statistical mechanics and material
 you flick that phenomena in a kind of precise reaction so I do some parts that are some kind of deepening of our study codes what I thought you said I can discuss that you can I will tell it too soon in Italian let me read it in English my idea in this moment is to follow me I will leave my problem as it is
 but I will flag some parts and they will be not compulsory I will tell you before I will put them in lectures that are separated and I will assure you that these lectures are independent from the rest of the program meaning that you can follow all the rest without any problem
 even if you don't come from the order of over 60 hours will be over the eight to ten hours and they will not be in the basic program of course I was thinking I will consider them only for the loan so I don't I don't want to tell because I got five but better I don't want to tell that it will become bad so you are getting a loan but I will do that
 if you come and don't report on these lectures it will be difficult you will have to be perfect not impossible but if you come with a full program then you can get the loan but I will count it only for the loan so I will not count in negative it for you at all that you don't bring this part to the exam so again I would want to
 If I have a discussion with you, I want to present the video. Because the first part of the program is based. So, if you want, you can put it in the list.
 And, so this is the first part of the program. So, this is the first part of the program.
 This is the first part of the program.
 This is the first part of the program.
 I will leave the program as well, but I will flag these lessons.
 They will not be obligated.
 I will give you the first part of the program.
 I will give you the first part of the program.
 I will give you the first part of the program.
 I will guarantee that those ones are all independent from the rest of the program.
 This program is not a problem or impact on the program.
 In any case, the first 20 hours are already complete.
 The first half of this course is in the transition phase.
 So it is quite standard.
 After that, for the exam,
 this will not exist on your vote, except on your note.
 Again, if you don't like it,
 I'm going to respond to your question.
 I don't want to say that you can't have the note
 if you don't have the note,
 but it's very difficult.
 Normally, if you want to have the note,
 you should have the note.
 But if you do the exam on the other side,
 I don't want to put the note on the note.
 I don't want to put limit to the providence in any way.
 I hope that this should bring to everyone,
 because I don't want everyone to make a statistician,
 I don't want to make an experiment,
 it's a very sensitive thing,
 I don't want to say too much,
 but I'm obligated to do it.
 But I want to give it to others
 because I want to grow in that sense.
 So I think this could be a good compromise.
 If you have any comments now you can put it or you can think about it and you can talk to me in public.
 Do you have any comments right now?
 Do you think following the group class helps with that part of the program?
 No, no, no, it will not be group theory at all.
 It will not be group theory at all.
 It is a group theory at all.
 It is more than 250, if you want.
 So, if you are taking a curriculum close to particle physics,
 or in general about abstract quantum theory, it is different.
 Group theory is indeed a very preliminary part of quantum theory,
 but not useful.
 So, group theory is really not connected,
 why the courses are closer at second and third of quantum theory.
 Any other questions?
 Okay, then I'm available for you.
 We'll see.
 I think that maybe the class will be enough.
 I think it has to change, but let's see how it feels good.
 So, what can I tell you more?
 Okay, so, this is an exam that is based on a book, basically a Parisi book.
 You find it on the network, you cannot even buy it, even if you want, you cannot use it.
 But if you find it on the network, this is no problem.
 And some parts are on a book, so one is Parisi, right? Statistical theory.
 And one is a book with the same title, I take a little bit to fix on that.
 And another one has the same title, and it is in six hours.
 I do this, this I will do it first. And then the same title, statistical figure.
 So these two, you get them, and then I don't write notes because I think that you do it in a book.
 And then there are many books around, of field theory, about field theory, and parts of the statistical field theory that apply to different cultures.
 You can come to me and we can discuss. The exam is typically an oral exam, very simple, with a simple structure.
 And I am very open-minded about when you can take it. Maybe some of you know me as a professor of the triennale.
 Here I am completely different. I mean, on the triennale, I am very tough, and I say exams will only be done at the end.
 Here you are done. So you basically do a response, meaning after the end of the course, I will typically, you can come every two weeks.
 And I'm open now, if you have to mark, it will not be a problem. So I will give you dates every month, every two months.
 I will tell you, I will like you, you can take the exam next week, in two weeks, and I will give you the time table.
 I say that on the noodle, so gold noodle, because of the noodle, there is a lot of material, there is material in two places, one is the noodle, of course, and one is by side, is Chimera, Roma 1, NF-NAT, so if you go to this side, Chimera slash Roma 1 dot Roma 1,
 and if you go there, we will find some cookie recipe, but you will also find the results listed in the scores.
 Okay? And there is one, because you know, the nearest score, so on, so everybody that wants to go and check things,
 you will find materials there, plus combination.
 But again, being the Moodle, because I will tell you, even if one day I cannot come teaching, for example, I will use Moodle today.
 Moodle, and again, the exam is very regular, and you can come and walk, and again, very open, very different.
 And again, I go back to English. Don't lose things because of English. You are losing something, you stop. You speak Italian to me.
 Well, if the course is in English, it's very good. But if you have any problems, you have a problem.
 If you have a problem, you have a problem, you have a problem, you have a problem, you have a problem.
 So, somehow, just two more words.
 So, this also will be phase transitions.
 And somehow we have to understand how this is a very very important phenomenon.
 In English, the understanding of this transition,
 that is an angle aimed at what is called a re-romanization of the rule,
 is probably one of the big theoretical compass of the last hundred years, in some sense.
 Because you somehow are able to understand, in a quantitative, mathematical way, a very complex situation.
 Because somehow it's a situation in which what you know about physics is typically theoretical.
 What is one of the Russian things about physics is locality.
 So I throw this piece of chalk on the wall and in New Zealand really nobody will care.
 I don't have to be in New Zealand, even there, nobody will care.
 Locality. What happens at this transition point, and this is for example where a metal develops a spontaneous magnetization,
 is that for some given values of the parameters of the system, and that you typically have pressure, human together,
 even if you are starting from a local direction, so you are assuming that each atom of the system only interacts with atoms that are very close,
 but the behavior of the system will be non-local, there will be what is called an infinite correlation of atoms.
 So the system will have a behavior in which if you touch something here,
 New Zealand has a problem, New Zealand is considered something, I don't know, a few millimeters maybe, but this is what it is.
 Okay, so again, this is from our point of view, right, because when we will see people, one of you will also follow field theory from a particular point of view,
 and we will see that this theoretical system describes both power systems and systems in particle physics,
 so somehow your understanding of microscopic reality is based on the same, exactly the same thing, right.
 Yes, okay, so first week we will try to understand this differentiation, we will define the models we use,
 and I told you there are viruses that are very bad, our main model will start with the Ising Model.
 We have heard about Ising Model.
 Quanti di voi avete sentito il denominato modello di Ising?
 Quanti di voi avete fatto un monte cario sul modello di Ising?
 Non so conoscere da Ising.
 So, here is a friendship with Ising Model.
 As you see, the harmonic oscillator of physics here.
 You know, the harmonic oscillator is the basic thing that you always use in physics, basically.
 You know also the harmonic oscillator.
 In this field, Ising Model.
 The variables that live on the lattice, so r is a lattice index,
 then you get the value plus or minus 1.
 So, we will start to study that.
 We will see that we will do some approximation,
 and we will find the same flow.
 The first decision, a second order of the first decision,
 which is important, where a non-locality belongs.
 So, you see, I start from this model, it is local, then I will be able to write it.
 The anitonium of this model will be minus, for example, sum,
 say over all couples of side-to-layer.
 So, let me call this side i, this side j.
 I promise you that the theory is local,
 which spin will be only seen nearby spins, right?
 So, sigma i, sigma j.
 So, for the opposite of numbers, sigma i, sigma j.
 So, this is where we told them, the spin,
 and then, okay, we will put it back.
 So, what are we going to do?
 Beta, okay?
 I don't know about it too far, but I mean, beta would be the inverse of the temperature.
 But, the main point is that, in medical temperature,
 this wants the spin to be unlimited.
 When there's temperature, then it starts to be potential.
 The only one that I wanted to do now is that this is an object.
 This is an object.
 On this spin, on this spin, on this spin, on this spin, on this spin.
 On this spin, on this spin, on this spin.
 On this spin, on this spin, on this spin.
 This is an image, a class X, a class X.
 For some value, some precise value of time,
 let's say we call it a temperature,
 this system will develop an effective infinite range interaction.
 So meaning, I will know that if I can start the system,
 I'm doing an experiment, right?
 I go on this thing, I kick it, I kick it,
 I look very far away and I will see that things change on this one.
 This is the phase transition. So, we will see that, for example, in a very simple approximation, we will find a phase transition.
 And then we will spend a few hours trying to understand all the features of this phase transition.
 And this will be basically the first part of our course, close to alphabet understanding.
 And then we will look for a way to understand this system better than in this first phase transition.
 And the method we will develop will be, again, renormalization.
 Theoretical dynamics of the 70s.
 Thanks to renormalization group, we will be able to compute some parameters and experiments
 that just measure with very high efficiency and fixed work.
 This is basically the magnet, then we will study the normalization group, first with what is called field theory,
 and then we will call space, x-space renormalization, x-space renormalization group.
 Yes, this is the basic line of course.
 Do you have any questions?
 I just need to understand if the system starts to exhibit an infinite correlation just at the critical level.
 That is a very good question. It is indeed only at the critical point.
 Very, very systems, in Parisi theory,
 disorderly systems can create systems where in a full phase you have an infinite correlation.
 So, this is high temperatures, the springs are basically a milliliter.
 You lower the temperature, correlation rate increases.
 So, you have large up to the critical temperature.
 In this point, you have an infinite correlation.
 When you decrease it, what happens?
 The system gets many times.
 You have this idea, right?
 So, when it's magnetization, you have the moment.
 And it is more or more.
 So, the system gets many times, meaning it can be in two states.
 So, in some sense, here also, when it's an infinite correlation rate,
 because we are in the plus state.
 So, if I have to bet with you, and you tell me this is plus,
 then I would bet against you that this is plus,
 and then there is an advantage that becomes larger,
 but it doesn't increase.
 But apart from this effect, that I can subtract by including the right things,
 which would be one of the main parts of our course in the next hours,
 apart from this effect, the correlation rate will start to increase.
 So, if I have to plot, yeah, this is a .
 So, this is the temperature. So, say, this is .
 So, I will have something like that.
 And then, if I take the line, the correct observable,
 meaning that eliminates this fact that I mean the class state or the minus state,
 if I take a correlation function, I will come to you and we can start with that.
 Also, notice that an important thing will be that it will be finite volume effects.
 So this is the correlation, finite volume effects.
 What does that mean? Sorry.
 So finite volume effects, what do we mean?
 So this is the correlation, but in which you are moving in a finite volume, for example the 2-Montecarlo, in 2 dimensions and you are doing 10 by 10.
 Can't the correlation then become as long as possible?
 How large can it become?
 Can it become, in a 10 by 10 lattice, can it become 1,000?
 No, because the lattice, yeah, it cannot be larger than L.
 It needs already L over 2 to start to be the H.
 So, when you are in a final point, what you measure is something like that.
 You do it on a larger lattice, so say this is, say, L equal infinity, say L equal L bar.
 And if you do it on L equal, for example, to L bar, you will find that far from the critical point, everything will be very similar.
 But when you go close to the critical point, things will change because the system will have more freedom.
 If you don't follow very well then, you don't care, I will teach about that.
 In any case, it's both of your friends.
 So, I told you that in a finished system, the length of the correlation will not become the same.
 You can't see it.
 You can't see it.
 You can't see it.
 Once I've done it, you can't see it.
 So, I've told you that if you've increased the length of the system,
 naturally the amount of correlation that the system can reach is increasing.
 If I do 10 and I do 20, I'm going to go to 20.
 We are in a situation where we are in an infinite volume, we assume that we are in an infinite volume.
 Siamo in situazioni in cui noi assumiamo che nel volume infinito abbiamo la linea di correlazione infinita.
 E sto argomentando che se il volume è finito la linea di correlazione deve essere finita.
 e cresce con il volume.
 Mi dico, di fiordà se hai dubbi di carri.
 Io lo seguo in italiano.
 E certo, abbiamo detto.
 C'è una lunghezza di correlazione.
 In chissà cosa rappresenta nel caso delle lingue.
 C'è la correlazione tra...
 Correlation length is no further.
 I have a system.
 I give you definition of correlation.
 There is a system.
 I perturb here.
 And I can see if there is an effect of a certain difference.
 At least one per mille of changes or something like that.
 At a certain distance.
 Ok?
 If there is a problem, the problem is that there is an exponential.
 So, the effects from the point where I put the perturbation are exponentially small in this way.
 Ok?
 When the correlation increases the effects go.
 So, this you can see as a definition, as a mathematical definition.
 You go in the system and experiment on a given definition.
 You measure a given distance and you see there is an effect.
 So, the smaller is a correlation length, the smaller will be the effect at a given firing distance.
 So, this is where we can do all this.
 You have a question about non-locality.
 If you change something here, it's global, but the change is faster than the light.
 What do you do in the local?
 Let me ask, this is nothing faster than the light.
 This is about the speed of the signal.
 I'm assuming that I'm at the speed of the signal.
 I've been waiting for quite a long time
 that the signal was given in the region of the space that I'm investigating.
 We are working in the context of this.
 It's a bit different from the theory of the background.
 So, I'm talking about a few minutes, I'm talking about a few hours, I'm talking about a few minutes, I'm talking about two hours, I'm talking about a few hours, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm talking about a few minutes, I'm
 I don't know what it is.
 I don't know what it is.
 So I start with Parisi chapter 1.
 And the first thing I will try to do with you is about to connect thermodynamics and statistical mechanics.
 You know very well thermodynamics. You know something about statistical mechanics.
 First, thermodynamics is what is called a "phenomenological science".
 What does it mean "phenomenological science"? Based on phenomena.
 If you think about it, I think maybe you've done a lot of thermodynamics, maybe you've never thought of it.
 When you do thermodynamics, you never see how things work.
 I mean, thermodynamics is indeed a very theoretical science.
 What do you see? You see, fine, there is a function that is the heat and this is integrable if I put a given factor,
 but you never see this is because one particle interacts with another with a given force. No way.
 Thermal dynamics is a phenomenological science in which you start from a request of mathematical consistency and you derive consequences.
 You're right, it's very warm. I don't know if we can do more, but there is a definition.
 Statistical mechanics is the opposite in some sense.
 In statistical mechanics you derive consequences from two main information.
 One is a Newtonian of interaction of particles or of degrees of freedoms that are fundamental to the theory.
 So, the physical mechanics, one, a Newtonian of particles.
 In general, it will be degrees of freedom, right?
 I will call them as particles, maybe just in the first lecture,
 but very soon they will be spins or then they will be feelings.
 I mean, they are degrees of freedom, degrees of freedom, okay?
 And to the fact that the particles are many.
 So, all the construction of statistical mechanics,
 okay, down, I mean, is derived from these two assumptions.
 This is the volume of interaction of microscopes with ease of freedom and the large number and the large number.
 So, you start from the equation of motions, equations of motion,
 of an elementary particle.
 So, somehow, in statistical mechanics, we derive the macroscopic properties
 of the system, starting by the law of motion of the components,
 of the individual microscopic components.
 And, again, the assumptions that they are made.
 Notice that many, I mean, in nature, you will discuss 10 to 23, right?
 That was what they teach you when they arrive here.
 Many is among our maps of this order.
 Indeed, when you go on computers, because now we have a lot of simulations
 and you discover typically that 10 to 9, 10 to 10,
 and it's already a large number.
 At this point, in this situation, the assumption is that you need probabilistic numbers.
 The thing you would say when I was a student and there were basically no computers, you
 would say how could you never solve 10 to 9 equations in 10 to 23.
 Today, you can easily solve 10 to 10 equations because you live in a completely different world.
 You will not even need to solve it, you will charge it with you, but you can solve it fine.
 But indeed somehow the problem is a bit irrelevant because we get the gas with 10 to 23 equations.
 What would you need in order to solve that?
 Do you have questions?
 Initial conditions.
 Is it reasonable to find a initial condition of 10 to 23 particles?
 So this is not what you can do, but also we don't care.
 Because at the end, we don't really carry the gas.
 What we carry is to derive macroscopic properties of the system.
 This is what we are...
 I don't know, let me do an example that then was very fast in the period of a disorderly system.
 You see, I have a glass. I let it fall in and it breaks in many pieces.
 And there will be 175 pieces one time, 250 another time, and they will scatter.
 And each time I break a glass, say I drink a glass of wine in the evening and then I get drunk and I take the glass,
 they will do something different. I don't really understand what exactly it does.
 If I produce a glass, I can typically see how far these little pieces go.
 Can they harm a kid that is around or anything like that?
 So the question that is more relevant is indeed a probabilistic question.
 So to try to understand which is the typical behavior of a macroscopic system,
 they talk to me about the equation that we have earlier.
 This is a very general property, meaning typically when you introduce a new technique,
 the questions themselves that is important to try to answer change.
 For example, computers, one very important part of our research, even our theoretical research,
 have changed completely.
 So we want to study the motion of our system in a probabilistic way.
 So let me call out some change notation. Let me start with the particles of notation.
 So, QP, generalized, momenta, so these are three-hand, three-hand, three-hand.
 In real world, they say that there is an equilibrium probability
 that is function of Q and Q.
 I mean, of all momenta, they call it as generalized momenta, of the system.
 I will use square brackets, and this will be a function,
 and we will do a very little, in the next lecture, after a bit,
 to indicate the dependence on all, say q, i, say i was from 1 to 3 n, for example,
 for a particle in form q, p, i, p, 2, 1 to 3 n, and to indicate the dependence
 from all these variables, I will use a square bracket.
 So my first point will be to determine the equilibrium of qp at large times.
 This is, again, a little answer to your colleague, right?
 I assume a label in this context. This is not always true.
 This is not always true, but I am very interested in physical cases
 in which I cannot reach such time to really prove the equilibrium distribution.
 Basically, this is a dynamical theory.
 What we are doing in this course, basically, is to assume that there is an equilibrium,
 an equilibrium distribution, and we can reach one.
 So, I will determine P equilibrium.
 P equilibrium is a probability distribution.
 So, it is a normalized function, we will go back to that.
 So, given this function, this probability distribution, P equilibrium of Qp,
 I determine the macroscopic properties of the system.
 Determine of the properties of the system.
 And I am using this Qp, but very soon it will now we will just call it C, the configuration.
 And I will just call it C, the configuration of the system that can be made.
 Okay, I think we can have a little break.
 See you soon.
 I'm going to go back to the next five minutes to stay here.
 So, normally we will have four hours a week, but for the first, I don't know, six hours a week.
 We have six hours, so we have in our set, in Marconi building, room number seven, we have four hours a week.
 I will not always use it, but sometimes, I guess, this week, we have started with six hours, so we know that it's in which, in which, in these six hours, it will be a big crash, and they will be a big crash.
 Do you have any questions before starting?
 I don't hear you about it.
 Okay.
 Normalmente, we have four elections, but in the first six weeks, in the middle of the normal state, we have six.
 That is, in the end of the week, we have six.
 I will use it several times, I will use it several times.
 No, I don't know.
 One more thing, normally I succeed to end before Christmas.
 No, I cannot guarantee it, but I mean, I try to do it because it's better.
 So we have some time to enjoy the vacation and don't care about it.
 But also, do it easy and start and to pass this exam faster.
 So, normally I try to do that.
 Again, I cannot guarantee it.
 Do you have any questions about what I say?
 Later on, let us continue.
 So, this object I have defined.
 Ah yes, I have a nice question.
 So, somehow the question I had was,
 this equilibrium distribution does depend on time.
 The answer is no after I am at equilibrium.
 At the start, this is a probability distribution.
 So, it doesn't mean that I am always the same microscopic contribution of the contrast.
 I will encounter a huge number of microscopic contributions.
 But, the equilibrium probability, what I call equilibrium probability,
 once I am in the equilibrium, will be considered.
 Oh, imagine I do a Monte Carlo, right?
 So this is the time of my Monte Carlo.
 Monte Carlo is living in real life, right?
 So, T, and here I put some tropics, some observable book of the system.
 So I put some particles in the box, and I measure, I don't know,
 it will change at the start, because when I start,
 I start from some random configuration, I don't know,
 so I put them there, I throw them in the box,
 maybe with random, and then I look at this observable.
 It will do something like that.
 It will change at the start,
 because when I've initialized the system,
 I did it around, or in some stupid way,
 but I will not show the behavior.
 The macroscopic property, because this is a generic,
 the macroscopic property will change.
 And then there will be a moment, say, let me give it our star,
 where I am at equilibrium.
 Now the system will oscillate,
 because of the system with the temperature,
 so I change configurations,
 and then it will stay around the same value of this offset.
 If I compute the expectation values,
 starting from this line,
 I will get to compute.
 Imagine I'm very dumb and I'm very busy.
 And I do want to determine T star
 and I want to start for T quasi.
 But I'm so easy that I wait a lot of time.
 Would I do a mistake in my average or not?
 I don't take the time, but I wait for a lot of time.
 Do I find the right result?
 Yes, because the time is infinite.
 The time that goes is an infinite time.
 But I will introduce a small error that dies as an inverse power of time,
 which is better for a lot because I pay for my computer time
 and I will introduce a small error that I have a small error that I have to use.
 I will introduce a small error that I have to use.
 I will not be able to use the same error.
 Transion is a part of the duration of time.
 What is important to say is that from this moment on
 I am at the time.
 So this is an important problem.
 The probability distribution
 of elemental use of freedom
 from this moment doesn't change anymore.
 The configuration of systems do change
 is the probability distribution that in this moment is coming.
 In this moment we have reached some temperature
 and then the particles move, but now the temperature is the same.
 Then maybe if a storm starts, it becomes very cold now,
 then I'm changing these standard parameters.
 And then also the temperature will change, meaning the properties of the particles will change.
 Okay, so my definition with P equilibrium is a probability distribution.
 So between T-sharp and other T, the probability of the equilibrium does not change the configuration.
 Yes, from this moment on, configurations always change. Configuration always change, right?
 If all these particles of air we have, freeze, what happens? If they stop, they don't stop.
 If they stop, they stop.
 They stop, they stop, they stop.
 Zero Kelvin, the cold, the cold.
 We don't want to be in the same configuration.
 But what is important is that from the moment on this configuration will be distributed
 always to be distributed.
 Let me tell you in a better way.
 Okay, so probability.
 The equilibrium is a distribution of probability.
 One, which means that all components are non-negative.
 And two, it is normalized to one.
 One by the other.
 Integral over all this dq/dp,
 and again I'm using square brackets
 to say I'm doing a huge number of integrations
 to condense it in a bunch of integrations.
 P, equilibrium,
 a dysfunction of goalbisq,
 or goalbisq,
 in qual cosa?
 - Però devo fessare il tempo io comunque.
 - Cioè, che vuol dire?
 - Cioè, quando io mi dato la probabilità di equilibrio,
 il tempo è fisso?
 - No, meglio su tutti i tempi nei quali sono all'equilibrio.
 Perché una volta, e vi ho spiegato che addirittura posso vedere su tutti i tempi,
 perché tanto un errore io ci metto per la mia pulizia, se ce lo metto scompare quando il tempo massimo va in più.
 Quindi io posso dire, once I've reached what I call vertistar, I am at equilibrio.
 This is a magic phrase.
 I am at equilibrio.
 I am at equilibrio means that the average properties of the system, and that reflect in the macroscopic properties,
 I measure the experiments, do not change anymore. So indeed, even better, and your question always leads me to say for t,
 this average of an equilibrio, for example I can see over as the sun, this is a possible way to define, for t going from this star
 to infinity, no, no, to large t of value of the servo of the t, 1 over t minus the star
 so that the value of the t is greater than the equilibrium.
 What I've told you is that if you do not include the first time,
 if you go to the T, you will not fail, because you will not be able to do the same thing,
 you will not be able to do the same thing.
 This is the probability.
 At this point, an important phrase,
 and then we will show why things were very bad.
 We assume that P equilibrium is the Boltzmann form.
 We are going to show why it is followed.
 That is P equilibrium of Q of P equal 1 over Zeta.
 Zeta is a coefficient function.
 Well, this is a normalization.
 This is a normalization factor.
 E minus beta H P Q.
 This is the basic of statistical economics.
 And we will show that we follow from a very simple principle of minimization.
 Zeta is a normalization function.
 And in this above, Zeta is the partition function.
 Zeta is a normalization factor, but this is the factor that guarantees that this thing is true.
 It guarantees that the integral of the low degrees of freedom of P equilibrium is what?
 So, this means that by definition, this is the integral over all these degrees of freedom of I to minus H.
 Again, this is the partition of H.
 We will see better and better during this course
 and basically the most part of the physics of the problem
 is included in this normalization function.
 So it's a normalization but it's a very important normalization.
 It contains typically more of what we can really compute.
 This is what is called the canonical distribution.
 Here is the canonical distribution of the canonical distribution.
 Vita is connected to the temperature.
 We have discussed in thermodynamics.
 In this moment, for us, thermodynamics and statistical mechanics are two different things.
 And this is not thermodynamics.
 I mean, what does thermodynamics know about the equation of motion?
 Thermodynamics is you have some functions,
 there are some mathematical inconsistencies requests,
 and you derive consequences.
 And now we are writing something based on the equation of motion
 and on the Russian .
 Then we will show that we need to approach our consistency,
 meaning that thermodynamic is realized in statistical mechanics.
 One of the crucial points of that is that this beta,
 that is at the moment a parameter we have talked about here,
 that you see as the dimension of one of an energy risk,
 this is the theoretical course.
 The dimension here will be very big.
 There will be some constants that we will ignore,
 we will know how important dimensions are.
 Dimensions are crucial.
 But this is saying to people,
 I don't know, that's a big picture,
 first year of the university,
 then now you know,
 but you don't forget.
 And when you know,
 you can hide away constants that cut dimensions.
 This is what we do now,
 because for example,
 I'll tell you here,
 it is a universe energy,
 as dimension one over kt,
 where k, without 20p is equal to 1,
 but k is Boltzmann constant,
 and it is close to 1.38,
 and then it is down in the scale,
 10 to minus 16 L.
 So, somehow k allows to connect an energy scale
 in a 10 generator scale.
 And, again, we will put it to 1 in the formula.
 And if 1 goes down minus 1,
 then we have to try to interpret Dolzman's distribution.
 And this has been...
 So, if you have a question,
 there is a lot of distribution.
 So, if you have a question,
 there is a lot of distribution.
 Sorry, do you have any questions or comments?
 What do I mean like that? You know, this has been a very important debate
 There is a problem with this probabilistic approach
 because we are starting from equation of motion
 and equation of motion conserves energy
 while what we are doing is to give a probability that is non-zero
 to configurations of different energies.
 The equation of motion conserves energy
 while in our approach conserves energy
 with Boltzmann
 probability different neutrons from zero
 for configurations of different energies.
 So this has been a very dramatic dispute.
 Again in 800 I will tell you which is the answer and you have seen it already.
 So now the answer is that in this approach we find the same answer that we have.
 Why? Maybe you have seen it. Okay, the statement is the following: in the limit of infinite volume, everything we will do in the following will basically be infinite volume.
 I tell you now, you write it on the first page of your notebook: phase transitions only exist in the infinite volume.
 Clearly, we are very close to the infinite volume and we can recognize everything that happens.
 We are discussing things that all infinite.
 You have seen last year that expectation values, computed with micro-canonical distribution,
 coincide with expectation values, computed with micro-canonical distribution,
 when the volume becomes simple.
 We have corrections that are on the border of one hand, on the baptism, on the entrance of power,
 but in the infinite volume, for an infinite number of particles, these two expectation values are on the side.
 What does it mean?
 And apart from finite size effects, if we compute the expectation value over fixed energy trajectories,
 or expectation value over energies distributed with Boltzmann, canonical, fixed energy, micro-canonical, Boltzmann, canonical,
 we find the same as our basic and formulas, I can write the equilibrium of the micro-canonical ensemble of QP
 in delta function of H minus A times P tilde, equilibrium as QP, micro-canonical,
 where a P equilibrium in the micro-canonical of QP is a constant.
 The statement that again we have discussed as P and I believe that lots of P
 is that the exponential values taken over
 the Boltzmann distribution, in the infinite volume coincide.
 So when I use a probability distribution that allows different energetic levels
 I am computing only the infinite volume limit, the same thing I am computing
 when I converge over different levels of different fixed energy.
 So this is an art I can do.
 Any question?
 Any question?
 Any more questions?
 I can't remember the problem.
 I can't remember the problem.
 I have been told that the probability of the postman has a probability of zero for configurations with energies different.
 Yes, because it seems like a bestiality, because when you look at the equation of the postman, the equation of the postman does not serve an energy.
 So I want to say: "But, excuse me, what do you do with this media on configurations of energies different?
 It is not the case of the postman, because the equation of the postman is of energy.
 And I would say no, because it is true that the distribution of Boltzmann is this,
 but it is true that in the limit of infinite volume,
 the value of the postman has a better distribution of the postman,
 which gives the minimum sense of the expectation,
 which is the micro-canonical distribution.
 But this micro-canonical distribution is equal to the postman of the postman.
 Let me start.
 And introduce you to the concept of entropy.
 Lentopia.
 This is a very important way to measure the disorder of our probability distribution.
 And what we want to do is to define, mathematically, the entropy of a given probability distribution.
 In this way, we will be able to start, for example, from Boltzmann's distribution to quantify how a given probability distribution is ordered,
 ordered or resolved. Let me start with it. Let me get Boltzmann probability and I know for sure that I'm in a given configuration.
 First question is: at what temperature would you imagine this character?
 When I go to zero temperature, the system freezes in a very high temperature,
 the system freezes in a very low temperature.
 So, in this case, I go to zero temperature.
 And again, which is in this case, the probability distribution.
 So, in a situation where I know exactly which configuration the system is,
 and this situation typically happens at zero temperature,
 I will get typically one given configuration,
 or we will see, maybe two, with my next one.
 When the temperature increases, the situation will be different.
 Basically, what will happen?
 There will be a temperature.
 The temperature in some way, some heat bath.
 They give some energy to the system.
 And the system will be with no zero probability allowed to be in a number of configurations.
 So, T plus zero, one stable configuration, one of few configurations.
 When T starts to be larger than zero, then configuration will be lower.
 And in order to compute it, I will have, you see, that would be typical of the minimum of energy, right?
 I don't know how it will give you that for you.
 Here I am basically to consider the free energy.
 What is the difference between the free energy and the free energy?
 There is no difference, right?
 The free energy is equal to U minus S.
 Ok, if you move it, right?
 So, F = U minus S.
 I put T = 0, I go to minimize F, I minimize the energy.
 So, I go to the minimum of energy and find my 0.
 When T is not 0, I will have to account for this entropy.
 These are concentrated here in the 5th, but...
 So, in this case, the entropy, when T is larger than 0,
 starts to be improper.
 So, now my idea is that I have to look at how many configurations are relevant, right?
 And if there are very few configurations, even if they are of very low energy,
 I will never find them. I will continue.
 So, let me start.
 Let me consider a set of configurations here.
 So, configurations will be the set of my degrees of freedom.
 It can be my own PQ, but it could be the set of the spins of my system for all the sides of my dimension.
 Again, this is how we do that.
 When we measure a probability measure a priori, then you see.
 For example, from the IC model, then you see that all my variables are binary, they can be plus one or minus one.
 So, here is the upper urination of IC.
 Then, there is another situation.
 H of C.
 And then, the infinitesimal probability.
 Sorry.
 He wrote measure...
 A measure de mu C.
 So...
 What is de mu?
 De mu C.
 I see de mu.
 Come?
 I didn't ask...
 It's a priori.
 Okay.
 Una probabilità a priori delle variabili.
 Per esempio, prendiamo Leasing.
 La probabilità a priori è che possa essere più 1 o meno 1 a 50%, a priori quali c'è il fattore.
 Quindi sarà un mezzo delta di sigma i più 1 più un mezzo delta di sigma del meno 1.
 Se ho campi reali sarà la misura piatta sui numeri reali.
 La misura che mi dice sostanzialmente lo spazio in cui le variabili vivono.
 Poi c'è la liturgiana.
 Now I'm able to write for you the definition of the basis of the parameter β that is the new c that will tell me something about the mythical variables.
 e to minus β, h of c, in this box of factor, over the partition function compute the inverse temperature.
 and the second one is c times d.
 That's not the random variable.
 Also, let me write it here.
 So, zeta and temperature of beta.
 I will typically not use beta here.
 This is just here to remind you that this is a given number of temperature.
 This is equal integral to values in i_h_c.
 And then I will have a expectation of values.
 A is an observable goal in this system.
 The temperature of Vita.
 And this will be the integral of the a priori measure of the variable.
 A, the value that observable A takes off configuration, C, times the probability, the Boltzmann probability of C.
 Ok, I will stop here.
 We will meet after tomorrow and we will meet the pandemic.
